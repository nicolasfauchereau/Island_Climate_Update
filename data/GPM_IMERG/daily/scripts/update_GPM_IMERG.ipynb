{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### os \n",
    "import os \n",
    "import sys\n",
    "\n",
    "### datetimes \n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "### scipy \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "### plotting \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "HOME = pathlib.Path.home()\n",
    "CWD = pathlib.Path.cwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trmm_grid(): \n",
    "    \n",
    "    import numpy as np \n",
    "    import xarray as xr \n",
    "    \n",
    "    lat_values = np.linspace(-59.875, 59.875, num=480, endpoint=True)\n",
    "    lon_values = np.linspace(-179.875, 179.875, num=1440, endpoint=True)\n",
    "    \n",
    "    d = {}\n",
    "    d['lat'] = (('lat'), lat_values)\n",
    "    d['lon'] = (('lon'), lon_values)\n",
    "    d = xr.Dataset(d)\n",
    "    return d      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_from_file(filename, sep='.',year_index=-4, month_index=-3, day_index=-2):\n",
    "    \n",
    "    from datetime import datetime, date\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    \n",
    "    if not type(filename) == pathlib.PosixPath: \n",
    "        filename = pathlib.Path(filename)\n",
    "     \n",
    "    # get the filename \n",
    "    fname = filename.name \n",
    "    \n",
    "    fname = fname.split('.')\n",
    "    \n",
    "    year = fname[year_index]\n",
    "    month = fname[month_index]\n",
    "    day = fname[day_index]\n",
    "    \n",
    "    d = list(map(int, [year, month, day])) \n",
    "    \n",
    "    d = date(*d)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates_to_download(dpath='/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP', realtime_lag=2): \n",
    "    \n",
    "    import pathlib\n",
    "    from datetime import datetime, date\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "    \n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    if not type(dpath) == pathlib.PosixPath: \n",
    "        dpath = pathlib.Path(dpath)    \n",
    "        \n",
    "    lfiles = list(dpath.glob(\"GPM_IMERG_daily.v06.????.??.??.nc\"))\n",
    "    \n",
    "    lfiles.sort()\n",
    "\n",
    "    last_file = lfiles[-1]\n",
    "    \n",
    "    last_date = get_date_from_file(last_file)\n",
    "    \n",
    "    today = date.today() \n",
    "    \n",
    "    download_date = today - relativedelta(days=realtime_lag)\n",
    "    \n",
    "    dates_to_download = pd.date_range(start=last_date, end=download_date, freq='1D')\n",
    "    \n",
    "    return dates_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_for_dates(dates, opath='/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP', proxy=None, lon_min=125., lon_max=240., lat_min=-55., lat_max=25.): \n",
    "    \n",
    "    import pathlib\n",
    "    from subprocess import call\n",
    "    from shutil import which \n",
    "    \n",
    "    curl = which(\"curl\") \n",
    "    \n",
    "    trmm_grid = make_trmm_grid()\n",
    "    \n",
    "    if not type(opath) == pathlib.PosixPath: \n",
    "        opath = pathlib.Path(opath)\n",
    "    \n",
    "    # first clean the *.nc4 files \n",
    "    \n",
    "    for nc4_file in list(opath.glob(\"*.nc4\")): \n",
    "        nc4_file.unlink()\n",
    "    \n",
    "    for date in dates:\n",
    "\n",
    "        root_url = f\"https://gpm1.gesdisc.eosdis.nasa.gov/data/GPM_L3/GPM_3IMERGDL.06/{date:%Y/%m}\"\n",
    "\n",
    "        fname = f\"3B-DAY-L.MS.MRG.3IMERG.{date:%Y%m%d}-S000000-E235959.V06.nc4\"\n",
    "\n",
    "        fname_out = f'GPM_IMERG_daily.v06.{date:%Y.%m.%d}.nc'\n",
    "\n",
    "        ### ==============================================================================================================\n",
    "        # build the command\n",
    "        if proxy:\n",
    "            cmd = f\"{curl} --silent --proxy {proxy} -n -c ~/.urs_cookies -b ~/.urs_cookies -L --url {root_url}/{fname} -o {opath}/{fname}\"\n",
    "        else:\n",
    "            cmd = f\"{curl} --silent -n -c ~/.urs_cookies -b ~/.urs_cookies -L --url {root_url}/{fname} -o {opath}/{fname}\"\n",
    "\n",
    "        print(cmd)\n",
    "\n",
    "        # execute the command\n",
    "        r = call(cmd, shell=True)\n",
    "\n",
    "        if r != 0:\n",
    "\n",
    "            print(\"download failed for date {:%Y-%m-%d}\".format(date))\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            stat_info = os.stat(os.path.join(opath,fname))\n",
    "\n",
    "            if stat_info.st_size > 800000:\n",
    "\n",
    "                dset_in = xr.open_dataset(os.path.join(opath,fname))\n",
    "\n",
    "                dset_in = dset_in[['HQprecipitation','precipitationCal']]\n",
    "\n",
    "                dset_in_interp = dset_in.interp_like(trmm_grid)\n",
    "\n",
    "                dset_in_interp = dset_in_interp.transpose('time','lat','lon')\n",
    "\n",
    "                # roll in the longitudes to go from -180 → 180 to 0 → 360\n",
    "\n",
    "                dset_in_interp = dset_in_interp.assign_coords(lon=(dset_in_interp.lon % 360)).roll(lon=(dset_in_interp.dims['lon'] // 2), roll_coords=True)\n",
    "\n",
    "                dset_in_interp = dset_in_interp.sel(lon=slice(lon_min, lon_max), lat=slice(lat_min, lat_max))\n",
    "\n",
    "                dset_in_interp.to_netcdf(opath.joinpath(fname_out),  unlimited_dims='time')\n",
    "                \n",
    "                opath.joinpath(fname).unlink()\n",
    "                                                    \n",
    "                dset_in.close()\n",
    "                dset_in_interp.close()\n",
    "                trmm_grid.close()\n",
    "\n",
    "            else:\n",
    "\n",
    "                print('\\n! file size for {0} does not match, netcdf file {0} probably not available from {1}\\n'.format(fname, root_url))\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dpath='/home/nicolasf/operational/ICU/ops/data/GPM_IMERG/daily/extended_SP', lon_min=125., lon_max=240., lat_min=-55., lat_max=25., proxy=None): \n",
    "    \n",
    "    trmm_grid = make_trmm_grid() \n",
    "    \n",
    "    dates = get_dates_to_download(dpath=dpath)\n",
    "    \n",
    "    download_for_dates(dates, opath=dpath, lon_min=lon_min, lon_max=lon_max, lat_min=lat_min, lat_max=lat_max, proxy=proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name == 'main':\n",
    "\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('-o','--dpath', dest='dpath', type=str, default=None, \\\n",
    "    help='the path where to find AND save the netcdf files, no default')\n",
    "\n",
    "    parser.add_argument('-p','--proxy', dest='proxy', type=str, default=None, \\\n",
    "    help='the proxy settings (url:port), default is None (no proxy)')\n",
    "\n",
    "    parser.add_argument('-lonW','--lon_min', dest='lon_min', type=float, default=125., \\\n",
    "    help='westernmost longitude for the domain to extract, default is 125.')\n",
    "\n",
    "    parser.add_argument('-lonE','--lon_max', dest='lon_max', type=float, default=240., \\\n",
    "    help='eastermost longitude for the domain to extract, default is 240.')\n",
    "\n",
    "    parser.add_argument('-latS','--lat_min', dest='lat_min', type=float, default=-50., \\\n",
    "    help='southermost latitude for the domain to extract, default is -50.')\n",
    "\n",
    "    parser.add_argument('-latN','--lat_max', dest='lat_max', type=float, default=25., \\\n",
    "    help='northermost latitude for the domain to extract, default is 25.')\n",
    "\n",
    "    vargs = vars(parser.parse_args())\n",
    "\n",
    "    # pop out the arguments\n",
    "\n",
    "    dpath = vargs['dpath']\n",
    "    proxy = vargs['proxy']\n",
    "    lon_min = vargs['lon_min']\n",
    "    lon_max = vargs['lon_max']\n",
    "    lat_min = vargs['lat_min']\n",
    "    lat_max = vargs['lat_max']\n",
    "    \n",
    "    main(dpath=dpath, lon_min=lon_min, lon_max=lon_max, lat_min=lat_min, lat_max=lat_max, proxy=proxy)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
